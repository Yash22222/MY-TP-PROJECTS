{
 "cells":[
  {
   "cell_type":"markdown",
   "source":[
    "# **TUTORIAL ON LANGCHAIN**\n",
    "\n",
    "\n",
    "### LLM 101 (HANDS ON)"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"ev6xnrTONAp7N3v07SIrGg",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "!pip install langchain huggingface_hub"
   ],
   "execution_count":1,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Collecting langchain\r\n",
      "  Downloading langchain-0.0.300-py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0\/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7\/1.7 MB\u001b[0m \u001b[31m52.8 MB\/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: huggingface_hub in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (0.16.4)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from langchain) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from langchain) (2.0.13)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from langchain) (3.8.4)\r\n",
      "Requirement already satisfied: anyio<4.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from langchain) (3.7.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from langchain) (4.0.3)\r\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\r\n",
      "  Downloading dataclasses_json-0.6.0-py3-none-any.whl (27 kB)\r\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\r\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\r\n",
      "Collecting langsmith<0.1.0,>=0.0.38 (from langchain)\r\n",
      "  Downloading langsmith-0.0.40-py3-none-any.whl (39 kB)\r\n",
      "Collecting numexpr<3.0.0,>=2.8.4 (from langchain)\r\n",
      "  Downloading numexpr-2.8.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (384 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0\/384.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.3\/384.3 kB\u001b[0m \u001b[31m32.2 MB\/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from langchain) (1.24.3)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from langchain) (2.3.0)\r\n",
      "Requirement already satisfied: requests<3,>=2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from langchain) (2.30.0)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from langchain) (8.2.3)\r\n",
      "Requirement already satisfied: filelock in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from huggingface_hub) (3.12.3)\r\n",
      "Requirement already satisfied: fsspec in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from huggingface_hub) (2023.6.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from huggingface_hub) (4.66.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from huggingface_hub) (4.7.1)\r\n",
      "Requirement already satisfied: packaging>=20.9 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from huggingface_hub) (23.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\r\n",
      "Requirement already satisfied: idna>=2.8 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from anyio<4.0->langchain) (3.4)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from anyio<4.0->langchain) (1.3.0)\r\n",
      "Requirement already satisfied: exceptiongroup in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from anyio<4.0->langchain) (1.1.3)\r\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\r\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0\/49.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4\/49.4 kB\u001b[0m \u001b[31m8.9 MB\/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\r\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\r\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\r\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from pydantic<3,>=1->langchain) (0.5.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from pydantic<3,>=1->langchain) (2.6.3)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests<3,>=2->langchain) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests<3,>=2->langchain) (2023.7.22)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\r\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\r\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\r\n",
      "Installing collected packages: numexpr, mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain\r\n",
      "Successfully installed dataclasses-json-0.6.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.300 langsmith-0.0.40 marshmallow-3.20.1 mypy-extensions-1.0.0 numexpr-2.8.6 typing-inspect-0.9.0\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"Ps1U02dRpUD4ybUqzMLC6p",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "For Hugging Face Models we need a **Hugging Face Hub API Token**.\n",
    "\n",
    "We can find this by first getting an account at [HuggingFace.co](https:\/\/huggingface.co\/) and clicking on our profile in the top-right corner > click *Settings* > click *Access Tokens* > click *New Token* > set *Role* to *write* > *Generate* > copy and paste the token below:"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"YSb97FWIYtOxtXQQkeugPt",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import os\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ],
   "execution_count":2,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"5BBIYMGLVoy34clNg4GlQd",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from langchain import HuggingFaceHub\n",
    "\n",
    "# Repo from HuggingFaceHub\n",
    "flan_t5 = HuggingFaceHub(repo_id = 'google\/flan-t5-xxl',\n",
    "                         model_kwargs={\"temperature\":0.1, \"max_new_tokens\":200})"
   ],
   "execution_count":3,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"4G4bpURvEMA8KXUzobEqRw",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# **Simple Prompt**"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"KatmypjQRNbOKvmIPVRhh6",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "prompt = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "\n",
    "Question: Which libraries and model providers offer LLMs?\n",
    "\n",
    "Answer: \"\"\""
   ],
   "execution_count":4,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"35pdvHAKfUfsPpweRWZO8E",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "flan_t5(prompt)"
   ],
   "execution_count":5,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "\"Hugging Face's transformers library, via OpenAI using the openai library, and via Cohere using the cohere library\""
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"s1U4m5Z5Q31MtBkFNryBX2",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# **Prompt Template**"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"yfZFKMvpeoab3rtINuHNFU",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=['query'],\n",
    "    template=template\n",
    ")"
   ],
   "execution_count":6,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"8AtPAySBbi6579kI1ShMmC",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "print(\n",
    "    prompt_template.format(\n",
    "        query = None\n",
    "    )\n",
    ")"
   ],
   "execution_count":7,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Answer the question based on the context below. If the\n",
      "question cannot be answered using the information provided answer\n",
      "with \"I don't know\".\n",
      "\n",
      "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
      "Their superior performance over smaller models has made them incredibly\n",
      "useful for developers building NLP enabled applications. These models\n",
      "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
      "using the `openai` library, and via Cohere using the `cohere` library.\n",
      "\n",
      "Question: None\n",
      "\n",
      "Answer: \n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"MVmtR1BVzRZYN4d9wo1hVI",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "print(flan_t5\n",
    "      (prompt_template.format(\n",
    "        query = 'where are llm used and which libraries and model provideers offer llms'\n",
    "    ))\n",
    "      )"
   ],
   "execution_count":8,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Hugging Face's transformers library, via OpenAI using the openai library, and via Cohere using the cohere library\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"bW2KSQ09TlWS7jVq1PT4am",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# **LLM Chain**"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"EfeJsjLGj2LRFLwecIPG6S",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "Chains are the core of LangChain. They are simply a chain of components, executed in a particular order.\n",
    "\n",
    "The simplest of these chains is the LLMChain. It works by taking a user's input, passing in to the first element in the chain — a PromptTemplate — to format the input into a particular prompt. The formatted prompt is then passed to the next (and final) element in the chain — a LLM."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"Ls8efEIWkirMQygiVZ3Gbb",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "template = \"\"\"Question: {question}\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ],
   "execution_count":9,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"xfD0ucqGqWebmY2KvVcegJ",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from langchain import LLMChain\n",
    "\n",
    "llm_chain = LLMChain(prompt = prompt, llm=flan_t5)"
   ],
   "execution_count":11,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"lGeLVYw7rNwFdKUQvNPPZL",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "question = \"Who is your creator?\"\n",
    "print(question)\n",
    "print(llm_chain.run(question))"
   ],
   "execution_count":12,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Who is your creator?\n",
      "God is the creator of all things. God is the creator of all life. Life is the ability to exist. So, the answer is God.\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"oyUpIJSaCltK6so2c28WSu",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "question = \"What is 2 * 5?\"\n",
    "print(question)\n",
    "print(llm_chain.run(question))"
   ],
   "execution_count":13,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "What is 2 * 5?\n",
      "2 * 5 is 5 because 2 is the product of 2 and 5. The answer: 5.\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"0SnMVuwXonZHnIA7sYwNkO",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "question = \"What NFL team won the Super Bowl in the year Justin Beiber was born?\"\n",
    "print(question)\n",
    "print(llm_chain.run(question))"
   ],
   "execution_count":15,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "What NFL team won the Super Bowl in the year Justin Beiber was born?\n",
      "The Super Bowl was won by the New England Patriots in the year Justin Beiber was born. The New England Patriots won the Super Bowl in the year Justin Beiber was born. The answer: the New England Patriots.\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"Z0gxz7pXpfOhEdk6IB4jDg",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    
   ],
   "report_row_ids":[
    
   ],
   "version":3
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}